<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
	<meta name="generator" content="Hugo 0.121.1">
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<title>Tobias Kirschstein</title>
<link rel="icon" type="image/x-icon" href="favicon.ico">

<link rel="stylesheet" href="/css/bulma.min.css" />



<link rel="stylesheet" href="/css/fontawesome.all.min.css" />
      <link rel="stylesheet" href="/css/main.min.ecd115d14e6a59a61722e58b19a7b298642267bdaaaeaa3f86444350a6d2e637.css" integrity="sha256-7NEV0U5qWaYXIuWLGaeymGQiZ72qrqo/hkRDUKbS5jc=" crossorigin="anonymous">



  <script src="/js/fontawesome.all.min.js"></script>
      <script src="/js/main.6d72b6274aae0ef6e0e7d1ad400ee9a8ed15b8ec1cd76fba2bd89a0637d1342a.js" integrity="sha256-bXK2J0quDvbg59GtQA7pqO0VuOwc12&#43;6K9iaBjfRNCo=" crossorigin="anonymous"></script>


</head>
<body>
  <header>
    <div id="navbar-wrapper">
    <nav id="navbar-main">
        <div class="container is-centered">
            <div class="columns">
                <div class="column is-narrow">
                    <a href="/" class="home-link is-size-5-mobile">Tobias Kirschstein</a>
                </div>
                <div class="column">
                    <span class="section-links">
                        <a href="#about" class="nav-link" data-target="#about">Home</a>
                        <a href="#publications" class="nav-link" data-target="#publications">Publications</a>
                        <a href="#teaching" class="nav-link" data-target="#teaching">Teaching</a>
                    </span>
                </div>
            </div>
        </div>
    </nav>
</div>
  </header>
  <main>
    

<section id="about" class="section section-about">
  <div class="container">
    <div class="columns">
      <div class="column is-4">
        <div class="profile-picture has-text-right-desktop has-text-centered-mobile">
          <div class="profile-picture-column">
            <img src="images/profile-512.jpg" style="width: 100%; max-width: 256px" />
            <div id="social-media-icons">
              
              <a href="mailto:tobias.kirschstein@tum.de">
                <div class="tooltip"><span class="tooltiptext">Mail</span>
                  <svg class=svg-icon width="32" height="32">
                    <use xlink:href="https://example.org/minima-social-icons.svg#email"></use>
                  </svg>
                </div>
              </a>
              <a href="CV.pdf" target="_blank">
                <div class="tooltip"><span class="tooltiptext">CV</span>
                  <svg class="svg-icon" width="32" height="32">
                    <use xlink:href="https://example.org/minima-social-icons.svg#resume"></use>
                  </svg>
                </div>
              </a>
              <a href="https://scholar.google.com/citations?user=rri0OT0AAAAJ" target="_blank">
                <div class="tooltip"><span class="tooltiptext">Google&nbsp;Scholar</span>
                  <svg class="svg-icon" width="32" height="32">
                    <use xlink:href="https://example.org/minima-social-icons.svg#googlescholar"></use>
                  </svg>
                </div>
              </a>
              <a href="https://github.com/tobias-kirschstein" target="_blank">
                <div class="tooltip"><span class="tooltiptext">GitHub</span>
                  <svg class="svg-icon" width="32" height="32">
                    <use xlink:href="https://example.org/minima-social-icons.svg#github"></use>
                  </svg>
                </div>
              </a>
              <a href="https://twitter.com/TobiasKirschst1" target="_blank">
                <div class="tooltip"><span class="tooltiptext">Twitter</span>
                  <svg class="svg-icon" width="32" height="32">
                    <use xlink:href="https://example.org/minima-social-icons.svg#twitter"></use>
                  </svg>
                </div>
              </a>
            </div>
          </div>
          </div>
        </div>

      <div class="column">
        <h1 class="title-me">Tobias Kirschstein</h1>
        PhD Student, Technical University of Munich
        <br /><br />
        <h2>About Me</h2>
        I am a PhD student in the <a href="https://niessnerlab.org/" target="_blank">Visual Computing & Artificial Intelligence Group</a> at the Technical University of Munich, supervised by <a href="https://niessnerlab.org/members/matthias_niessner/profile.html" target="_blank">Prof. Matthias Nießner</a>.
        <br /><br />
        I am the creater and maintainer of the <a href="https://tobias-kirschstein.github.io/nersemble/" target="_blank">NeRSemble dataset</a>, for which I built a custom multi-view setup with 16 video cameras and recorded facial expressions of over 250 individuals.
        Since its release, the dataset has enabled various research projects around 3D head avatars.<a data-target="modal-nersemble-citations" class="js-modal-trigger"><sup>1</sup></a>
        <br /><br />
        Before starting my PhD, I completed a M.Sc. degree in Informatics at TU Munich with my Master’s Thesis focusing on Neural Rendering for novel-view synthesis on outdoor scenes using sparse point clouds.
        I obtained a B.Sc. degree in both Mathematics and Computer Science at the University of Passau, where I studied how Deep Learning can be used for emotion recognition from physiological signals under the supervision of <a href="http://www.schuller.one/" target="_blank">Prof. Björn Schuller</a>.
        <br /><br />
        My current research interests lie in Neural Rendering, 3D Scene Representations, Dynamic 3D Reconstruction and Animatable 3D Head Avatars.
      </div>
    </div>
  </div>
</section>

<div id="modal-nersemble-citations" class="modal">
  <div class="modal-background"></div>
  <div class="modal-card">
    <header class="modal-card-head">
      <p class="modal-card-title">NeRSemble dataset</p>
      <button class="delete" aria-label="close"></button>
    </header>
    <section class="modal-card-body">
      Selection of projects building on the NeRSemble dataset:
      <ul>
        <li><a href="https://yuelangx.github.io/gaussianheadavatar/" target="_blank">Gaussian Head Avatar: Ultra High-fidelity Head Avatar via Dynamic Gaussians</a></li>
        <li><a href="https://tobias-kirschstein.github.io/diffusion-avatars/" target="_blank"> Diffusion Avatars: Deferred Diffusion for High-fidelity 3D Head Avatars </a></li>
        <li><a href="https://shenhanqian.github.io/gaussian-avatars" target="_blank">GaussianAvatars: Photorealistic Head Avatars with Rigged 3D Gaussians</a></li>
        <li><a href="https://arxiv.org/pdf/2401.08398.pdf" target="_blank">High-Quality Mesh Blendshape Generation from Face Videos via Neural Inverse Rendering</a></li>
        <li><a href="https://freedomgu.github.io/DiffPortrait3D/" target="_blank">DiffPortrait3D: Controllable Diffusion for Zero-Shot Portrait View Synthesis</a></li>
      </ul>
    </section>
    <footer class="modal-card-foot">
      <button class="button">Close</button>
    </footer>
  </div>
</div>

<section id="publications" class="section">
  <div class="container">
    <div class="hr"><div class="tk"></div></div>
  </div>
  <div class="container">
    <h2 class="section-header">Publications</h2>
  </div>
  <div class="container">
    <div class="publications">
      
      
      
      
      <div class="publication columns">

        <div class="column is-4">
          
          
          <div class="publication-cover">
            <img src="/publications/2024-diffusion-avatars/cover.jpg" class="hover-1"/>
            
            <video autoplay="" loop="" muted="" playsinline="" class="hover-2" >
              <source src="/publications/2024-diffusion-avatars/cover.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
            
          </div>
        </div>

        <div class="column">
          
          
          <h3 class="publication-title"> DiffusionAvatars: Deferred Diffusion for High-fidelity 3D Head Avatars</h3>

          
          <div class="publication-conference">CVPR 2024</div>




          
          <div class="publication-description">
            <p>DiffusionAvatar uses diffusion-based, deferred neural rendering to translate geometric cues from an underlying neural parametric head model (NPHM) to photo-realistic renderings.
The underlying NPHM provides accurate control over facial expressions, while the deferred neural rendering leverages the 2D prior of StableDiffusion, in order to generate compelling images.</p>

          </div>

          
          <div class="publication-authors">
            <span class="author-me">Tobias Kirschstein</span>, Simon Giebenhain, Matthias Nießner
          </div>

          
          <div class="publication-links">
            
            <span class="publication-link"><a href="https://tobias-kirschstein.github.io/diffusion-avatars/" target="_blank">Project</a></span>
            
            <span class="publication-link"><a href="https://arxiv.org/pdf/2311.18635.pdf" target="_blank">Paper</a></span>
            
            <span class="publication-link"><a href="https://youtu.be/nSjDiiTnp2E" target="_blank">Video</a></span>
            
            
            
            <span class="publication-link"><a data-target="modal-bibtex-2024-diffusion-avatars" class="js-modal-trigger">Bibtex</a></span>
            
          </div>
        </div>
      </div>

      
      
      <div id="modal-bibtex-2024-diffusion-avatars" class="modal">
        <div class="modal-background"></div>
        <div class="modal-card">
          <header class="modal-card-head">
            <p class="modal-card-title">Cite</p>
            <button class="delete" aria-label="close"></button>
          </header>
          <section class="modal-card-body">
            
            <pre><code id="bibtex-2024-diffusion-avatars">@article{kirschstein2023diffusionavatars,
  title={DiffusionAvatars: Deferred Diffusion for High-fidelity 3D Head Avatars},
  author={Kirschstein, Tobias and Giebenhain, Simon and Nie{\ss}ner, Matthias},
  journal={arXiv preprint arXiv:2311.18635},
  year={2023}
}</code></pre>
          </section>
          <footer class="modal-card-foot">
            <a href="publications/2024-diffusion-avatars/kirschstein2024diffusionavatars.bib" class="button button-color"><span class="icon"><i class="fas fa-download"></i></span><span>Download</span></a>
            <button class="button button-color js-copy-clipboard" data-target="bibtex-2024-diffusion-avatars"><span class="icon"><i class="fas fa-copy"></i></span><span>Copy</span></button>
            <button class="button">Close</button>
          </footer>
        </div>
      </div>
      

      
      
      <div class="publication columns">

        <div class="column is-4">
          
          
          <div class="publication-cover">
            <img src="/publications/2024-gaussian-avatars/cover.jpg" class="hover-1"/>
            
            <video autoplay="" loop="" muted="" playsinline="" class="hover-2" >
              <source src="/publications/2024-gaussian-avatars/cover.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
            
          </div>
        </div>

        <div class="column">
          
          
          <h3 class="publication-title">GaussianAvatars: Photorealistic Head Avatars with Rigged 3D Gaussians</h3>

          
          <div class="publication-conference">CVPR 2024</div>




          
          <div class="publication-description">
            <p>GaussianAvatars rigs 3D Gaussians to a parametric mesh model for photorealistic avatar creation and animation.
During avatar reconstruction, the morphable model parameters and Gaussian splats are optimized jointly in an end-to-end fashion from video recordings.
GaussianAvatars can then be animated through expression transfer from a driving sequence or by manually changing the morphable model parameters.</p>

          </div>

          
          <div class="publication-authors">
            Shenhan Qian, <span class="author-me">Tobias Kirschstein</span>, Liam Schoneveld, Davide Davoli, Simon Giebenhain, Matthias Nießner
          </div>

          
          <div class="publication-links">
            
            <span class="publication-link"><a href="https://shenhanqian.github.io/gaussian-avatars" target="_blank">Project</a></span>
            
            <span class="publication-link"><a href="https://arxiv.org/pdf/2312.02069.pdf" target="_blank">Paper</a></span>
            
            <span class="publication-link"><a href="https://www.youtube.com/watch?v=lVEY78RwU_I" target="_blank">Video</a></span>
            
            
            
            <span class="publication-link"><a data-target="modal-bibtex-2024-gaussian-avatars" class="js-modal-trigger">Bibtex</a></span>
            
          </div>
        </div>
      </div>

      
      
      <div id="modal-bibtex-2024-gaussian-avatars" class="modal">
        <div class="modal-background"></div>
        <div class="modal-card">
          <header class="modal-card-head">
            <p class="modal-card-title">Cite</p>
            <button class="delete" aria-label="close"></button>
          </header>
          <section class="modal-card-body">
            
            <pre><code id="bibtex-2024-gaussian-avatars">@article{qian2023gaussianavatars,
  title={GaussianAvatars: Photorealistic Head Avatars with Rigged 3D Gaussians},
  author={Qian, Shenhan and Kirschstein, Tobias and Schoneveld, Liam and Davoli, Davide and Giebenhain, Simon and Nie{\ss}ner, Matthias},
  journal={arXiv preprint arXiv:2312.02069},
  year={2023}
}</code></pre>
          </section>
          <footer class="modal-card-foot">
            <a href="publications/2024-gaussian-avatars/qian2023gaussianavatars.bib" class="button button-color"><span class="icon"><i class="fas fa-download"></i></span><span>Download</span></a>
            <button class="button button-color js-copy-clipboard" data-target="bibtex-2024-gaussian-avatars"><span class="icon"><i class="fas fa-copy"></i></span><span>Copy</span></button>
            <button class="button">Close</button>
          </footer>
        </div>
      </div>
      

      
      
      <div class="publication columns">

        <div class="column is-4">
          
          
          <div class="publication-cover">
            <img src="/publications/2024-mono-nphm/cover.jpg" class="hover-1"/>
            
            <video autoplay="" loop="" muted="" playsinline="" class="hover-2" >
              <source src="/publications/2024-mono-nphm/cover.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
            
          </div>
        </div>

        <div class="column">
          
          
          <h3 class="publication-title">MonoNPHM: Dynamic Head Reconstruction from Monoculuar Videos</h3>

          
          <div class="publication-conference">CVPR 2024</div>




          
          <div class="publication-description">
            <p>MonoNPHM is a neural parametric head model that disentangles geomery, appearance and facial expression into three separate latent spaces.
Using MonoNPHM as a prior, we tackle the task of dynamic 3D head reconstruction from monocular RGB videos, using inverse, SDF-based, volumetric rendering.</p>

          </div>

          
          <div class="publication-authors">
            Simon Giebenhain, <span class="author-me">Tobias Kirschstein</span>, Markos Georgopoulos, Martin Rünz, Lourdes Agapito, Matthias Nießner
          </div>

          
          <div class="publication-links">
            
            <span class="publication-link"><a href="https://simongiebenhain.github.io/MonoNPHM/" target="_blank">Project</a></span>
            
            <span class="publication-link"><a href="https://simongiebenhain.github.io/MonoNPHM/static/MonoNPHM.pdf" target="_blank">Paper</a></span>
            
            <span class="publication-link"><a href="https://www.youtube.com/watch?v=n-wjaC3UIeE" target="_blank">Video</a></span>
            
            
            
            <span class="publication-link"><a data-target="modal-bibtex-2024-mono-nphm" class="js-modal-trigger">Bibtex</a></span>
            
          </div>
        </div>
      </div>

      
      
      <div id="modal-bibtex-2024-mono-nphm" class="modal">
        <div class="modal-background"></div>
        <div class="modal-card">
          <header class="modal-card-head">
            <p class="modal-card-title">Cite</p>
            <button class="delete" aria-label="close"></button>
          </header>
          <section class="modal-card-body">
            
            <pre><code id="bibtex-2024-mono-nphm">@misc{giebenhain2023mononphm,
    title={MonoNPHM: Dynamic Head Reconstruction from Monoculuar Videos},
    author={Simon Giebenhain and Tobias Kirschstein and Markos Georgopoulos and  Martin R{\&#34;{u}}nz and Lourdes Agapito and Matthias Nie{\ss}ner},
    year={2023}
    publisher={arXiv},
    primaryClass={cs.CV}
}</code></pre>
          </section>
          <footer class="modal-card-foot">
            <a href="publications/2024-mono-nphm/giebenhain2023mononphm.bib" class="button button-color"><span class="icon"><i class="fas fa-download"></i></span><span>Download</span></a>
            <button class="button button-color js-copy-clipboard" data-target="bibtex-2024-mono-nphm"><span class="icon"><i class="fas fa-copy"></i></span><span>Copy</span></button>
            <button class="button">Close</button>
          </footer>
        </div>
      </div>
      

      
      
      <div class="publication columns">

        <div class="column is-4">
          
          
          <div class="publication-cover">
            <img src="/publications/2023-nersemble/cover.jpg" class="hover-1"/>
            
            <video autoplay="" loop="" muted="" playsinline="" class="hover-2" >
              <source src="/publications/2023-nersemble/cover.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
            
          </div>
        </div>

        <div class="column">
          
          
          <h3 class="publication-title">NeRSemble: Multi-view Radiance Field Reconstruction of Human Heads</h3>

          
          <div class="publication-conference">Siggraph 2023</div>




          
          <div class="publication-description">
            <p>NeRSemble reconstructs high-fidelity dynamic radiance fields of human heads.
We combine a deformation for coarse movements with an ensemble of 3D multi-resolution hash encodings. These act as a form of expression-dependent volumetric textures that model fine-grained, expression-dependent details.
Additionally, we propose a new 16 camera multi-view capture dataset (7.1 MP resolution and 73 frames per second) containing 4700 sequences of more than 220 human subjects.</p>

          </div>

          
          <div class="publication-authors">
            <span class="author-me">Tobias Kirschstein</span>, Shenhan Qian, Simon Giebenhain, Tim Walter, Matthias Nießner
          </div>

          
          <div class="publication-links">
            
            <span class="publication-link"><a href="https://tobias-kirschstein.github.io/nersemble/" target="_blank">Project</a></span>
            
            <span class="publication-link"><a href="https://arxiv.org/pdf/2305.03027.pdf" target="_blank">Paper</a></span>
            
            <span class="publication-link"><a href="https://youtu.be/a-OAWqBzldU" target="_blank">Video</a></span>
            
            <span class="publication-link"><a href="https://github.com/tobias-kirschstein/nersemble" target="_blank">Code</a></span>
            
            <span class="publication-link"><a href="https://forms.gle/rYRoGNh2ed51TDWX9" target="_blank">Dataset</a></span>
            
            
            
            <span class="publication-link"><a data-target="modal-bibtex-2023-nersemble" class="js-modal-trigger">Bibtex</a></span>
            
          </div>
        </div>
      </div>

      
      
      <div id="modal-bibtex-2023-nersemble" class="modal">
        <div class="modal-background"></div>
        <div class="modal-card">
          <header class="modal-card-head">
            <p class="modal-card-title">Cite</p>
            <button class="delete" aria-label="close"></button>
          </header>
          <section class="modal-card-body">
            
            <pre><code id="bibtex-2023-nersemble">@article{kirschstein2023nersemble,
    author = {Kirschstein, Tobias and Qian, Shenhan and Giebenhain, Simon and Walter, Tim and Nie\ss{}ner, Matthias},
    title = {NeRSemble: Multi-View Radiance Field Reconstruction of Human Heads},
    year = {2023},
    issue_date = {August 2023},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {42},
    number = {4},
    issn = {0730-0301},
    url = {https://doi.org/10.1145/3592455},
    doi = {10.1145/3592455},
    journal = {ACM Trans. Graph.},
    month = {jul},
    articleno = {161},
    numpages = {14},
}</code></pre>
          </section>
          <footer class="modal-card-foot">
            <a href="publications/2023-nersemble/kirschstein2023nersemble.bib" class="button button-color"><span class="icon"><i class="fas fa-download"></i></span><span>Download</span></a>
            <button class="button button-color js-copy-clipboard" data-target="bibtex-2023-nersemble"><span class="icon"><i class="fas fa-copy"></i></span><span>Copy</span></button>
            <button class="button">Close</button>
          </footer>
        </div>
      </div>
      

      
      
      <div class="publication columns">

        <div class="column is-4">
          
          
          <div class="publication-cover">
            <img src="/publications/2023-nphm/cover.jpg" class="hover-1"/>
            
            <video autoplay="" loop="" muted="" playsinline="" class="hover-2" >
              <source src="/publications/2023-nphm/cover.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
            
          </div>
        </div>

        <div class="column">
          
          
          <h3 class="publication-title">NPHM: Learning Neural Parametric Head Models</h3>

          
          <div class="publication-conference">CVPR 2023</div>




          
          <div class="publication-description">
            <p>NPHM is a field-based neural parametric model for human heads, which represents identity geometry implicitly in a cononical space and models expressions as forward deformations.
The SDF in canonical space is represented as an ensemble of local MLPs centered around facial anchor points.
To train our model, we capture a large dataset of complete head geometry containing over 250 people in 23 expressions each, using high quality structured light scanners.</p>

          </div>

          
          <div class="publication-authors">
            Simon Giebenhain, <span class="author-me">Tobias Kirschstein</span>, Markos Georgopoulos, Martin Rünz, Lourdes Agapito, Matthias Nießner
          </div>

          
          <div class="publication-links">
            
            <span class="publication-link"><a href="https://simongiebenhain.github.io/NPHM/" target="_blank">Project</a></span>
            
            <span class="publication-link"><a href="https://simongiebenhain.github.io/NPHM/static/NPHM.pdf" target="_blank">Paper</a></span>
            
            <span class="publication-link"><a href="https://www.youtube.com/watch?v=0mDk2tFOJCg" target="_blank">Video</a></span>
            
            <span class="publication-link"><a href="https://github.com/SimonGiebenhain/NPHM#learning-neural-parametric-head-models-nphm" target="_blank">Code</a></span>
            
            <span class="publication-link"><a href="https://forms.gle/66xWfAxzCvsoqcNZ8" target="_blank">Dataset</a></span>
            
            
            
            <span class="publication-link"><a data-target="modal-bibtex-2023-nphm" class="js-modal-trigger">Bibtex</a></span>
            
          </div>
        </div>
      </div>

      
      
      <div id="modal-bibtex-2023-nphm" class="modal">
        <div class="modal-background"></div>
        <div class="modal-card">
          <header class="modal-card-head">
            <p class="modal-card-title">Cite</p>
            <button class="delete" aria-label="close"></button>
          </header>
          <section class="modal-card-body">
            
            <pre><code id="bibtex-2023-nphm">@inproceedings{giebenhain2023nphm,
    author={Simon Giebenhain and Tobias Kirschstein and Markos Georgopoulos and  Martin R{\&#34;{u}}nz and Lourdes Agapito and Matthias Nie{\ss}ner},
    title={Learning Neural Parametric Head Models},
    booktitle = {Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)},
    year = {2023}
}</code></pre>
          </section>
          <footer class="modal-card-foot">
            <a href="publications/2023-nphm/giebenhain2023nphm.bib" class="button button-color"><span class="icon"><i class="fas fa-download"></i></span><span>Download</span></a>
            <button class="button button-color js-copy-clipboard" data-target="bibtex-2023-nphm"><span class="icon"><i class="fas fa-copy"></i></span><span>Copy</span></button>
            <button class="button">Close</button>
          </footer>
        </div>
      </div>
      

      
      
      <div class="publication columns">

        <div class="column is-4">
          
          
          <div class="publication-cover">
            <img src="/publications/2021-code-transformer/cover.jpg" class="hover-single"/>
            
          </div>
        </div>

        <div class="column">
          
          
          <h3 class="publication-title">Language-agnostic representation learning of source code from structure and context</h3>

          
          <div class="publication-conference">ICLR 2021</div>




          
          <div class="publication-description">
            <p>We present CodeTransformer, which combines source code (Context) and parsed abstract syntax trees (ASTs; Structure) for representation learning on code.
Code and Structure are two complementary representations of the same computer program, and we show the benefit of combining both for the task of method name prediction.
To achieve this, we propose an extension to transformer architectures that can handle both graph and sequential inputs.</p>

          </div>

          
          <div class="publication-authors">
            Daniel Zügner, <span class="author-me">Tobias Kirschstein</span>, Michele Catasta, Jure Leskovec, Stephan Günnemann
          </div>

          
          <div class="publication-links">
            
            <span class="publication-link"><a href="https://arxiv.org/pdf/2103.11318.pdf" target="_blank">Paper</a></span>
            
            <span class="publication-link"><a href="https://iclr.cc/virtual/2021/poster/2838" target="_blank">Video</a></span>
            
            <span class="publication-link"><a href="https://github.com/danielzuegner/code-transformer" target="_blank">Code</a></span>
            
            <span class="publication-link"><a href="http://code-transformer.org/" target="_blank">Demo</a></span>
            
            <span class="publication-link"><a href="https://iclr.cc/media/iclr-2021/Slides/2838.pdf" target="_blank">Slides</a></span>
            
            
            
            <span class="publication-link"><a data-target="modal-bibtex-2021-code-transformer" class="js-modal-trigger">Bibtex</a></span>
            
          </div>
        </div>
      </div>

      
      
      <div id="modal-bibtex-2021-code-transformer" class="modal">
        <div class="modal-background"></div>
        <div class="modal-card">
          <header class="modal-card-head">
            <p class="modal-card-title">Cite</p>
            <button class="delete" aria-label="close"></button>
          </header>
          <section class="modal-card-body">
            
            <pre><code id="bibtex-2021-code-transformer">@inproceedings{zuegner2021codetransformer,
  author       = {Daniel Z{\&#34;{u}}gner and
                  Tobias Kirschstein and
                  Michele Catasta and
                  Jure Leskovec and
                  Stephan G{\&#34;{u}}nnemann},
  title        = {Language-Agnostic Representation Learning of Source Code from Structure and Context},
  booktitle    = {9th International Conference on Learning Representations, {ICLR} 2021,
                  Virtual Event, Austria, May 3-7, 2021},
  year         = {2021},
  url          = {https://openreview.net/forum?id=Xh5eMZVONGF},
}</code></pre>
          </section>
          <footer class="modal-card-foot">
            <a href="publications/2021-code-transformer/zuegner2021codetransformer.bib" class="button button-color"><span class="icon"><i class="fas fa-download"></i></span><span>Download</span></a>
            <button class="button button-color js-copy-clipboard" data-target="bibtex-2021-code-transformer"><span class="icon"><i class="fas fa-copy"></i></span><span>Copy</span></button>
            <button class="button">Close</button>
          </footer>
        </div>
      </div>
      

      
      
      <div class="publication columns">

        <div class="column is-4">
          
          
          <div class="publication-cover">
            <img src="/publications/2017-emotion-recognition/cover.jpg" class="hover-single"/>
            
          </div>
        </div>

        <div class="column">
          
          
          <h3 class="publication-title">End-to-end learning for dimensional emotion recognition from physiological signals</h3>

          
          <div class="publication-conference">ICME 2017</div>




          
          <div class="publication-description">
            <p>We show that end-to-end Deep Learning can replace traditional feature engineering in the signal processing domain.
Not only does a combination of convolutional layers and LSTMs perform better for the task of emotion recognition, we also demonstrate that some cells’ activations in the convolutional network are highly correlated with hand-crafted features.</p>

          </div>

          
          <div class="publication-authors">
            Gil Keren, <span class="author-me">Tobias Kirschstein</span>, Erik Marchi, Fabien Ringeval, Björn Schuller
          </div>

          
          <div class="publication-links">
            
            <span class="publication-link"><a href="https://opus.bibliothek.uni-augsburg.de/opus4/frontdoor/deliver/index/docId/71917/file/71917.pdf" target="_blank">Paper</a></span>
            
            
            
            <span class="publication-link"><a data-target="modal-bibtex-2017-emotion-recognition" class="js-modal-trigger">Bibtex</a></span>
            
          </div>
        </div>
      </div>

      
      
      <div id="modal-bibtex-2017-emotion-recognition" class="modal">
        <div class="modal-background"></div>
        <div class="modal-card">
          <header class="modal-card-head">
            <p class="modal-card-title">Cite</p>
            <button class="delete" aria-label="close"></button>
          </header>
          <section class="modal-card-body">
            
            <pre><code id="bibtex-2017-emotion-recognition">@inproceedings{keren2017end,
  title={End-to-end learning for dimensional emotion recognition from physiological signals},
  author={Keren, Gil and Kirschstein, Tobias and Marchi, Erik and Ringeval, Fabien and Schuller, Bj{\&#34;o}rn},
  booktitle={2017 IEEE International Conference on Multimedia and Expo (ICME)},
  pages={985--990},
  year={2017},
  organization={IEEE}
}</code></pre>
          </section>
          <footer class="modal-card-foot">
            <a href="publications/2017-emotion-recognition/keren2017endtoend.bib" class="button button-color"><span class="icon"><i class="fas fa-download"></i></span><span>Download</span></a>
            <button class="button button-color js-copy-clipboard" data-target="bibtex-2017-emotion-recognition"><span class="icon"><i class="fas fa-copy"></i></span><span>Copy</span></button>
            <button class="button">Close</button>
          </footer>
        </div>
      </div>
      

      
      
    </div>
  </div>
</section>
<section id="teaching" class="section">
  <div class="container">
    <div class="hr"><div class="tk"></div></div>
  </div>
  <div class="container">
    <h2 class="section-header">Teaching</h2>
  </div>
  <div class="container">
    <div class="teachings">
      

      
      <div class="teaching columns">
        <div class="column is-6">
          
          <h3 class="teaching-title">
            
              <a href="https://campus.tum.de/tumonline/ee/ui/ca2/app/desktop/#/slc.tm.cp/student/courses/950699059?$ctx=design=ca;lang=en&amp;$scrollTo=toc_overview" target="_blank">3D Scanning &amp; Spatial Learning Practical</a>
            
          </h3>

          
          <div>
            <span class="teaching-role">Instructor</span> - <span class="teaching-semester">Winter Semester 2023/24</span>
          </div>
        </div>

        <div class="column">
          
          <div class="teaching-description">
            <p>Offered and supervised projects for teams of 2-3 students on the following topics:</p>

          </div>

          
          <ul class="teaching-projects">
            
            <li>Codec Avatars for Teleconferencing</li>
            
            <li>Intuitive Face Animation through Sparse Deformation Components</li>
            
            <li>Multi-view Stereo via Inverse Rendering</li>
            
            <li>Synthetic 3D Hair Reconstruction</li>
            
          </ul>
        </div>
      </div>
      
      <div class="teaching columns">
        <div class="column is-6">
          
          <h3 class="teaching-title">
            
              <a href="https://campus.tum.de/tumonline/ee/ui/ca2/app/desktop/#/slc.tm.cp/student/courses/950670318?$ctx=design=ca;lang=en&amp;$scrollTo=toc_overview" target="_blank">3D Scanning &amp; Spatial Learning Practical</a>
            
          </h3>

          
          <div>
            <span class="teaching-role">Instructor</span> - <span class="teaching-semester">Summer Semester 2023</span>
          </div>
        </div>

        <div class="column">
          
          <div class="teaching-description">
            <p>Offered and supervised projects for teams of 2-4 students on the following topics:</p>

          </div>

          
          <ul class="teaching-projects">
            
            <li>3D Face Reconstruction and Tracking</li>
            
            <li>Intuitive Speech-driven Face Animation</li>
            
            <li>Reconstructing surfaces with NeuS and Deep Marching Tetrahedra</li>
            
            <li>Multi-view 3D Hair Reconstruction</li>
            
          </ul>
        </div>
      </div>
      
      
    </div>
  </div>
</section>
<section id="teaching" class="section">
  <div class="container">
    <div class="hr"><div class="tk"></div></div>
  </div>
  <div class="container">
    <h2 class="section-header">Reviewing</h2>
  </div>
  <div class="container">
    <div class="reviewing">
      
      
      
      <div class="review columns is-centered is-mobile">
        <div class="column is-half-desktop">
          
          <h3 class="review-title has-text-centered">
            CVPR
          </h3>
          <div class="reviewing-conference-name has-text-centered">IEEE/CVF Computer Vision and Pattern Recognition Conference</div>

          
          <div class="columns is-centered is-mobile">
            <ul class="reviews column is-half">
              
              <li>2024: 4 papers</li>
              
            </ul>
          </div>
        </div>
      </div>
      
      
    </div>
  </div>
</section>


  </main>
  <footer>
    <p>&copy; 2024 Tobias Kirschstein</p>

  </footer>
</body>
</html>
